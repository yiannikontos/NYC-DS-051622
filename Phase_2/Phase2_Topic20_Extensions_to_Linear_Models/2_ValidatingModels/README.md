# Model Validation

## Learning Goals

- Explain the bias-variance tradeoff and the correlative notions of underfit and overfit models
- Describe a train-test split and explain its purpose in the context of predictive statistics / machine learning
- Explain the algorithm of cross-validation

## Lecture Materials

[Jupyter Notebook: Model Validation](model_validation.ipynb)

## Lesson Plan

### Motivation (5 Mins)

Discuss the importance of model validation, tying it to the "real world"/"wild".

### The Bias-Variance Tradeoff (15 Mins)

Explain what it means to have high/low bias & variance. Conclude with an example of simple vs complex models

### Train-Test Split (20 Mins)

Go over motivation and how train-test split helps. Couple exercies within (first short; second is a bit longer); could be done as a large group.

### k-Fold Cross-Validation: Even More Rigorous Validation (15 Mins)

Explain how cross-validation fits with train-test split and how it should be used (for validation of model).
